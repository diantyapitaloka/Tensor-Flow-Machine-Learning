## âš¡ğŸ’§â˜ƒï¸ Tensor Flow Machine Learning â˜ƒï¸ğŸ’§âš¡ 
This dataset contains images of hand gestures from the Rock-Paper-Scissors game. The images were captured as part of a hobby project where I developped a Rock-Paper-Scissors game using computer vision and machine learning on the Raspberry Pi

Here are few images taken from the dataset:

![image](https://github.com/diantyapitaloka/Tensor-Flow-Machine-Learning/assets/147487436/1b92d61c-d940-49ac-aabb-5d6aa94afec5)

## âš¡ğŸ’§â˜ƒï¸ Convolutional Neural Network (CNN) â˜ƒï¸ğŸ’§âš¡ 

Convolutional Neural Network (CNN for short) is one of the most popular technique in image classification.

CNN are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply.

The difference is CNN architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.

![image](https://github.com/diantyapitaloka/Tensor-Flow-Machine-Learning/assets/147487436/1cd62f84-ea6e-4bf2-9cc7-bd1945361d08)

## âš¡ğŸ’§â˜ƒï¸ Contents â˜ƒï¸ğŸ’§âš¡ 
The dataset contains a total of 2188 images corresponding to the 'Rock' (726 images), 'Paper' (710 images) and 'Scissors' (752 images) hand gestures of the Rock-Paper-Scissors game. All image are taken on a green background with relatively consistent ligithing and white balance.

## âš¡ğŸ’§â˜ƒï¸ Format â˜ƒï¸ğŸ’§âš¡ 
All images are RGB images of 300 pixels wide by 200 pixels high in .png format. The images are separated in three sub-folders named 'rock', 'paper' and 'scissors' according to their respective class.

## âš¡ğŸ’§â˜ƒï¸ L â˜ƒï¸ğŸ’§âš¡ 
## âš¡ğŸ’§â˜ƒï¸ L â˜ƒï¸ğŸ’§âš¡ 
## âš¡ğŸ’§â˜ƒï¸ L â˜ƒï¸ğŸ’§âš¡ 
## âš¡ğŸ’§â˜ƒï¸ L â˜ƒï¸ğŸ’§âš¡ 
## âš¡ğŸ’§â˜ƒï¸ References â˜ƒï¸ğŸ’§âš¡ 

[1] https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html

[2] https://cs231n.github.io/convolutional-networks/

[3] https://deepai.org/machine-learning-glossary-and-terms/max-pooling

[4] https://towardsdatascience.com/understanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa

[5] https://keras.io/api/callbacks/reduce_lr_on_plateau/

[6] https://keras.io/api/optimizers/adam/
